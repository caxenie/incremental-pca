{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Machine Learning on \n",
    "# Evolving Non-stationary Data Streams\n",
    "\n",
    "## Intuition, Formalism and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "jupyter nbconvert StreamingML.ipynb --to slides --post serve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stream Processing\n",
    "\n",
    "Given a sequence of data (a stream), a series of operations (functions) is applied to each element in the stream, in a declarative way, we specify what we want to achieve and not how [Bifet, 2010].\n",
    "![](streaming-intuition.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stream processing\n",
    "\n",
    "Data __Stream Learning__ is more challenging than __batch or offline learning__ [Bifet, 2010]:\n",
    "* The amount of data is __extremely large__, potentially infinite - __impossible to store__ it all. \n",
    "* Only a __small summary__ can be computed and stored, and the rest is discarded - unfeasible to go over it for processing.\n",
    "* The __speed of arrival is high__, so that each particular element has to be processed in __real time__, and then discarded.\n",
    "* The __distribution generating the items__ can __change over time__. \n",
    "* __Data from the past__ may become __irrelevant (or even harmful)__for the current summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stream processing\n",
    "\n",
    "![](ml-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond i.i.d\n",
    "\n",
    "* __Traditional machine learning and data mining__ assume the current observed data and the future data are assumed to be i.i.d\n",
    "* __Data samples__, past and current data samples do not affect the probability for future ones. \n",
    "\n",
    "* Applications like:\n",
    "    * web mining, \n",
    "    * social networks, \n",
    "    * network monitoring, \n",
    "    * sensor networks, \n",
    "    * telecommunications, \n",
    "    * financial forecasting, etc.\n",
    "* Data samples arrive __continuously__, __online__ through unlimited streams often at __high speed, over time__\n",
    "* The __process__ generating these data streams __may evolve over time__ (evolving, nonstationarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond i.i.d\n",
    "\n",
    "In order to deal with evolving data streams, the model learnt from the streaming data must capture up-to-date trends and transient patterns in the stream. \n",
    "\n",
    "Updating the model by incorporating new examples, we must also eliminate the effects of outdated examples representing outdated concepts through one-pass.\n",
    "\n",
    "Types of change\n",
    "![](changes-types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond i.i.d\n",
    "\n",
    "In order to deal with evolving data streams, the model learnt from the streaming data must capture up-to-date trends and transient patterns in the stream. \n",
    "\n",
    "Typical changes in classification\n",
    "![](changes-sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond i.i.d\n",
    "\n",
    "When __training and test data__ follow __different probability distributions__, but the __conditional distributions of output__ values given input points are __unchanged__, is called the __covariate shift__ [Sugiyama et al., 2012]. The __target function__ is __unchanged__, but the __distributions__ are __different__ between the training and testing.\n",
    "\n",
    "![](covariate-shift.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond i.i.d\n",
    "\n",
    "The key idea of __covariate shift adaptation__ is to (softly) __choose informative training samples__ in a systematic way, by considering the __importance__ of each training sample in the prediction of test output values, namely the ratio\n",
    "\n",
    "$$ \\frac{p_{te}(x_i^{tr})}{p_{tr}(x_i^{tr})}$$\n",
    "\n",
    "Basically, __the expectation__ of a function $f$ (i.e. regression) over $x_{te}$ can be computed by the __importance-weighted expectation__ of the function over $x_{tr}$. Thus, the __difference of distributions__ can be systematically __adjusted__ by importance weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concept drift\n",
    "\n",
    "Data generated by phenomena in __nonstationary environments__ are characterized by: \n",
    "\n",
    "* potentially unlimited size;\n",
    "* sequential access to data samples (i.e. once an observation has been processed, it cannot be retrieved);\n",
    "* unpredictable, dependent, and not identical distributed observations.\n",
    "\n",
    "__Learning from streams of nonstationary data__ lives under the following constraints[Sayed-Mouchaweh, 2016]:\n",
    "* __Random access to observations__ is __not feasible__, or it has high costs (i.e. dataset not a priori available or too large).\n",
    "* __Memory is small__ with respect to the size of data.\n",
    "* Data __distribution__ generating the data may __evolve over time__. This is also known as __concept drift__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incremental learning\n",
    "\n",
    "Unlike __conventional machine learning__, the __data flow__ targeted by __incremental learning__ becomes available __continuously__ over time and needs to be __processed in a single pass__.\n",
    "\n",
    "The inherent __challenges__ here are: \n",
    "\n",
    "* __data availability__ \n",
    "* __model update__ \n",
    "* __data size__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incremental learning\n",
    "\n",
    "The inherent __challenges__ here are: \n",
    "\n",
    "* __data availability__ - new data is received and eliminated from the window of interest as the stream evolves in time\n",
    "* __model update__ - given the dynamics of the window evolution, the updates must be performed in a single pass\n",
    "* __data size__ - precise models need large windows, yet updating the model for the entire window is costly in terms of latency and resource allocation (i.e. memory / disk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incremental dimensionality reduction (PCA)\n",
    "\n",
    "In a __structured form__, the basic formulation, PCA follows the following steps:\n",
    "\n",
    "![](basic-pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incremental dimensionality reduction (PCA)\n",
    "\n",
    "![](basic-pca-problems.png)\n",
    "\n",
    "Tackle the __inherent problems in traditional PCA__ impeding it to achieve __low latency, high throughput and fixed memory/storage__:\n",
    "* Calculation of the __mean and other descriptive statistics__ as the data is available.\n",
    "* __Sorting the dominant eigenvalues__ in the rank update of the QR decomposition.\n",
    "* Calculating the __covariance matrix__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Towards incremental PCA\n",
    "\n",
    "Incremental __calculation of the mean and other descriptive statistics__ on the datastream.\n",
    "![](streaming-mean.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Towards incremental PCA\n",
    "\n",
    "Incremental __updates depending on counts (i.e. histogram)__, which contain sorted eigenvalues.\n",
    "![](streaming-histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Towards incremental PCA\n",
    "\n",
    "Incremental __estimation of the covariance matrix__, as __neural synaptic weights__ converge to the eigenvectors (unique set of __optimal weights__ and __uncorrelated outputs__) [Axenie et al., 2019]\n",
    "![](streaming-neural-covariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Towards incremental PCA\n",
    "\n",
    "Converge from an initially __random set of synaptic weights__ to the __eigenvectors of the input autocorrelation__ in the eigenvalues order __minimizing the linear reconstruction (i.e. using Linear Least Squares)__. \n",
    "![](streaming-lls.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example implementation\n",
    "\n",
    "### Multi-class classification task (fault identification in predictive maintenance [Axenie et al., 2019])\n",
    "\n",
    "We used a __real-world stream__ with 6 types of sensory readings from a coal coke prediction production line data:\n",
    "\n",
    "![](coke.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example implementation\n",
    "\n",
    "### Multi-class classification task (fault identification in predictive maintenance [Axenie et al., 2019])\n",
    "\n",
    "__Goal__: __identify faults__ in the production line by __querying the eigenvalues and eigenvectors__ to extract the normal and faulty operation configuration __prior to a multi-class classifier__. \n",
    "\n",
    "The datastream:\n",
    "* 2M incoming events at 40 kHz. \n",
    "* eigenvalues of the input $X$ are close to the class labels (i.e. $1, 2, ..., d$)\n",
    "* eigenvectors are close to the canonical basis of $R^d$, where $d$ is the number of principal components to extract\n",
    "* class number for the multi-class classification task (i.e. 10 classes, 9 faults and 1 normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example implementation\n",
    "\n",
    "### Multi-class classification task (fault identification in predictive maintenance [Axenie et al., 2019])\n",
    "\n",
    "![](experimental-setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PCA vs. Incremental PCA (Latency Analysis)\n",
    "\n",
    "![](latency-analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PCA vs. Incremental PCA (Throughput Analysis)\n",
    "\n",
    "![](throughput-analysis-abs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PCA vs. Incremental PCA (Throughput Analysis)\n",
    "\n",
    "![](throughput-analysis-hist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PCA vs. Incremental PCA (Accuracy Analysis)\n",
    "\n",
    "![](accuracy-analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "* __low-latency__ (1-ms level), __high-throughput__ (Kevents/s) computation and __learning on datastreams__,\n",
    "\n",
    "* __incremental PCA model__ and leveraging __stream dimensionality reduction__ on a distributed system,\n",
    "\n",
    "* computation of __statistical features__ and __neural learning rules__ \n",
    "\n",
    "* __guaranteeing limited or programmable resource__ allocation (i.e. memory and disk),\n",
    "\n",
    "* validated in __predictive maintenance__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "[Bifet, 2010] Albert Bifet - Adaptive Stream Mining Pattern Learning and Mining from Evolving Data Streams, IOS Press, 2010.\n",
    "\n",
    "[Sugiyama et al., 2012] Masashi Sugiyama, Motoaki Kawanabe - Machine Learning in Non-Stationary Environments Introduction to Covariate Shift Adaptation-The MIT Press, 2012.\n",
    "\n",
    "[Sayed-Mouchaweh, 2016] Moamar Sayed-Mouchaweh - Learning from Data Streams in Dynamic Environments-Springer International Publishing, 2016.\n",
    "\n",
    "[Axenie et al., 2019] C. Axenie, Radu Tudoran, Stefano Bortoli, Mohamad Al Hajj Hassan, Alexander Wieder, Goetz Brasche, SPICE: Streaming PCA fault Identification and Classification Engine in Predictive Maintenance, IoT Stream Workshop, European Conf. on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2019).\n",
    "\n",
    "[Weng et al., 2003] J. Weng, Y. Zhang, and W.-S. Hwang, “Candid covariance-free incremental principal component analysis,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 25, no. 8, pp. 1034–1040, 2003.\n",
    "\n",
    "[Brand, 2002] M. Brand, “Incremental singular value decomposition of uncertain data with missing values.” in ECCV (1), ser. Lecture Notes in Computer Science, A. Heyden, G. Sparr, M. Nielsen, and P. Johansen, Eds., vol. 2350. Springer, 2002, pp. 707–720."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Standard PCA implementation (QR-decomposition based)\n",
    "# The gain vector gamma determines the weight placed on the new data in updating each principal\n",
    "# component. The first coefficient of gamma corresponds to the first principal component, etc. It can\n",
    "# be specified as a single positive number (which is recycled by the function) or as a vector of length\n",
    "# ncol(U). For larger values of gamma, more weight is placed on x and less on U. A common choice\n",
    "# for (the components of) gamma is of the form c/n, with n the sample size and c a suitable positive constant.\n",
    "StreamPCAModelsState StandardPCA (StreamPCAModelsState state, SimpleMatrix x){\n",
    "\n",
    "        // recover state\n",
    "        SimpleMatrix lambda = state.getLambda();\n",
    "        SimpleMatrix Q = state.getQ();\n",
    "\n",
    "        int ind = state.getN();\n",
    "        SimpleMatrix gamma = new SimpleMatrix(Q.numCols(), 1);\n",
    "        for (int id = 0; id < Q.numCols(); id++) {\n",
    "            gamma.set(id, 1.0);\n",
    "        }\n",
    "        gamma = gamma.scale(1.0 / (ind * ind));\n",
    "        SimpleMatrix xbar = state.getXbar();\n",
    "\n",
    "        // update the average\n",
    "        state.setXbar(this.updateIncrementalDataMean(xbar, x, ind));\n",
    "        xbar = state.getXbar();\n",
    "\n",
    "        // for the update remove the average\n",
    "        x = x.minus(xbar).transpose();\n",
    "\n",
    "        // update the predictor\n",
    "        SimpleMatrix y = Q.mult(x);\n",
    "\n",
    "        SimpleMatrix W;\n",
    "        SimpleMatrix Qupd = Q;\n",
    "        SimpleMatrix evidence = (x.mult(y.transpose()));\n",
    "        SimpleMatrix gammaDiag = gamma.diag();\n",
    "        SimpleMatrix increment = evidence.mult(gammaDiag);\n",
    "        Qupd = Qupd.plus(increment);\n",
    "\n",
    "        // decomposition\n",
    "        QRDecomposition<DMatrixRMaj> qrDecomp = DecompositionFactory_DDRM.qr(Qupd.numRows(), Qupd.numCols());\n",
    "        qrDecomp.decompose(Qupd.getMatrix());\n",
    "        W = SimpleMatrix.wrap(qrDecomp.getQ(null, true));\n",
    "\n",
    "        SimpleMatrix decay = ((gamma.minus(1.0)).scale(-1.0)).elementMult(lambda);\n",
    "        SimpleMatrix incrementLambda = gamma.elementMult(y).elementMult(y);\n",
    "        lambda = incrementLambda.plus(decay);\n",
    "\n",
    "        // wrap return values\n",
    "        state.setLambda(lambda);\n",
    "        state.setQ(W);\n",
    "        return state;\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# QR decomposition\n",
    "\n",
    "        QRDecomposition<DMatrixRMaj> alg = createQRDecomposition();\n",
    "\n",
    "        SimpleMatrix A = new SimpleMatrix(height,width, DMatrixRMaj.class);\n",
    "        RandomMatrices_DDRM.fillUniform((DMatrixRMaj)A.getMatrix(),rand);\n",
    "\n",
    "        assertTrue(alg.decompose((DMatrixRMaj)A.copy().getMatrix()));\n",
    "\n",
    "        int minStride = Math.min(height,width);\n",
    "\n",
    "        SimpleMatrix Q = new SimpleMatrix(height,compact ? minStride : height, DMatrixRMaj.class);\n",
    "        alg.getQ((DMatrixRMaj)Q.getMatrix(), compact);\n",
    "        SimpleMatrix R = new SimpleMatrix(compact ? minStride : height,width, DMatrixRMaj.class);\n",
    "        alg.getR((DMatrixRMaj)R.getMatrix(), compact);\n",
    "\n",
    "\n",
    "        // see if Q has the expected properties\n",
    "        assertTrue(MatrixFeatures_DDRM.isOrthogonal((DMatrixRMaj)Q.getMatrix(), UtilEjml.TEST_F64_SQ));\n",
    "\n",
    "        // see if it has the expected properties\n",
    "        DMatrixRMaj A_found = Q.mult(R).getMatrix();\n",
    "\n",
    "        EjmlUnitTests.assertEquals((DMatrixRMaj)A.getMatrix(),A_found,UtilEjml.TEST_F64_SQ);\n",
    "        assertTrue(Q.transpose().mult(A).isIdentical(R,UtilEjml.TEST_F64_SQ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-071c2e542ee4>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-071c2e542ee4>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    StreamPCAModelsState NeuralPCA(StreamPCAModelsState state, SimpleMatrix x){\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Neural PCA implementation\n",
    "# The vector gamma determines the weight placed on the new data in updating each eigenvector (the\n",
    "# first coefficient of gamma corresponds to the first eigenvector, etc). It can be specified as a single\n",
    "# positive number or as a vector of length ncol(U). Larger values of gamma place more weight on\n",
    "# x and less on U. A common choice for (the components of) gamma is of the form c/n, with n the\n",
    "# sample size and c a suitable positive constant.\n",
    "\n",
    "StreamPCAModelsState NeuralPCA(StreamPCAModelsState state, SimpleMatrix x){\n",
    "\n",
    "        // recover state\n",
    "        SimpleMatrix lambda = state.getLambda();\n",
    "        SimpleMatrix Q = state.getQ();\n",
    "        int ind = state.getN();\n",
    "        SimpleMatrix gamma = new SimpleMatrix(Q.numCols(), 1);\n",
    "        for (int id = 0; id < Q.numCols(); id++) {\n",
    "            gamma.set(id, 1.0);\n",
    "        }\n",
    "        gamma = gamma.scale(1.0 / (ind * ind));\n",
    "        SimpleMatrix xbar = state.getXbar();\n",
    "\n",
    "        // update the average\n",
    "        state.setXbar(this.updateIncrementalDataMean(xbar, x, ind));\n",
    "        xbar = state.getXbar();\n",
    "\n",
    "        // for the update remove the average\n",
    "        x = x.minus(xbar).transpose();\n",
    "\n",
    "        // update the predictor\n",
    "        SimpleMatrix y = Q.mult(x);\n",
    "\n",
    "        // prepare new state\n",
    "        int m = Q.numRows(), n = Q.numCols();\n",
    "        SimpleMatrix gamy = gamma.elementMult(y); // Schur product\n",
    "        SimpleMatrix b = Q.extractVector(false, 0).scale(y.get(0));\n",
    "        SimpleMatrix A = new SimpleMatrix(m,n);\n",
    "        A.setColumn(0, 0,\n",
    "                (Q.extractVector(false, 0)\n",
    "                        .minus(b.scale(gamy.get(0))))\n",
    "                        .getDDRM()\n",
    "                        .data);\n",
    "        for (int i=1; i<n; i++) {\n",
    "            b = b.plus(Q.extractVector(false, i).scale(y.get(i)));\n",
    "            A.setColumn(i, 0,\n",
    "                    (Q.extractVector(false, i)\n",
    "                            .minus(b.scale(gamy.get(i))))\n",
    "                            .getDDRM()\n",
    "                            .data);\n",
    "        }\n",
    "        A = A.plus(x.mult(gamy.transpose()));\n",
    "        SimpleMatrix decay = ((gamma.minus(1.0)).scale(-1.0)).elementMult(lambda);\n",
    "        SimpleMatrix increment = gamma.elementMult(y).elementMult(y);\n",
    "        lambda = increment.plus(decay);\n",
    "\n",
    "        // wrap return values\n",
    "        state.setLambda(lambda);\n",
    "        state.setQ(A);\n",
    "        return state;\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
